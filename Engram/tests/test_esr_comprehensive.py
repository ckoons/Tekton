#!/usr/bin/env python3
"""
Comprehensive ESR Test - Full validation of the ESR system.
"""

import asyncio
import sys
import os
from pathlib import Path
from datetime import datetime
import json

# Setup paths
sys.path.insert(0, str(Path(__file__).parent.parent))
sys.path.insert(0, str(Path(__file__).parent.parent.parent))
os.environ['TEKTON_ROOT'] = str(Path(__file__).parent.parent.parent)

print("="*70)
print("COMPREHENSIVE ESR SYSTEM TEST")
print("="*70)


async def test_store_everywhere_detailed():
    """Detailed test of store everywhere paradigm."""
    print("\nüîç STORE EVERYWHERE PARADIGM TEST")
    print("-"*40)
    
    from engram.core.storage.universal_encoder import UniversalEncoder, MemoryResponse
    
    # Create mock backends with verification
    class VerifiableBackend:
        def __init__(self, name):
            self.name = name
            self.data = {}
            self.store_count = 0
            self.retrieve_count = 0
        
        async def store(self, key, value, metadata=None):
            self.data[key] = {"value": value, "metadata": metadata}
            self.store_count += 1
            print(f"   [{self.name}] Stored key '{key}'")
            return True
        
        async def retrieve(self, key):
            self.retrieve_count += 1
            if key in self.data:
                return MemoryResponse(
                    content=self.data[key]["value"],
                    source_backend=self.name,
                    retrieval_time=0.01,
                    confidence=1.0,
                    metadata=self.data[key].get("metadata", {})
                )
            return None
    
    # Create 5 different backends
    backends = {
        'vector_db': VerifiableBackend('vector_db'),
        'graph_db': VerifiableBackend('graph_db'),
        'sql_db': VerifiableBackend('sql_db'),
        'document_db': VerifiableBackend('document_db'),
        'cache_db': VerifiableBackend('cache_db')
    }
    
    encoder = UniversalEncoder(backends=backends)
    
    # Test 1: Store multiple memories
    print("\nüìù Storing multiple memories...")
    test_memories = [
        ("mem_001", {"thought": "The sky is blue", "type": "observation"}),
        ("mem_002", {"thought": "Water flows downhill", "type": "fact"}),
        ("mem_003", {"thought": "AI can learn patterns", "type": "insight"})
    ]
    
    for key, content in test_memories:
        results = await encoder.store_everywhere(key, content, {"timestamp": datetime.now().isoformat()})
        successful = sum(1 for s in results.values() if s)
        print(f"   ‚úì {key}: Stored in {successful}/{len(backends)} backends")
    
    # Verify all backends have all data
    print("\nüîé Verifying storage across backends...")
    all_stored = True
    for backend_name, backend in backends.items():
        stored_count = len(backend.data)
        print(f"   {backend_name}: {stored_count} memories, {backend.store_count} store operations")
        if stored_count != len(test_memories):
            all_stored = False
    
    if all_stored:
        print("   ‚úÖ All memories stored in ALL backends!")
    
    # Test 2: Recall and synthesis
    print("\nüîÑ Testing recall from everywhere...")
    for key, _ in test_memories:
        synthesis = await encoder.recall_from_everywhere(key=key)
        sources = len([b for b in backends.values() if b.retrieve_count > 0])
        print(f"   {key}: Retrieved from {sources} sources, synthesis: {synthesis.get('status', 'unknown')}")
    
    # Get statistics
    stats = encoder.get_statistics()
    print(f"\nüìä Statistics:")
    print(f"   Total stores: {stats['stats']['total_stores']}")
    print(f"   Total recalls: {stats['stats']['total_recalls']}")
    
    return all_stored


async def test_frequency_promotion_detailed():
    """Detailed test of frequency-based promotion."""
    print("\nüîÑ FREQUENCY-BASED PROMOTION TEST")
    print("-"*40)
    
    from engram.core.storage.cache_layer import CacheLayer
    
    cache = CacheLayer(
        max_size=5,
        promotion_threshold=2,
        eviction_policy='lru',
        persist_cache=False
    )
    
    # Store multiple items
    print("\nüìù Storing items in cache...")
    items = []
    for i in range(3):
        key = await cache.store(
            content=f"Memory item {i}",
            content_type='test',
            metadata={'index': i},
            ci_id=f'ci_{i}'
        )
        items.append(key)
        print(f"   Stored: {key[:8]}... = 'Memory item {i}'")
    
    # Test promotion at different access levels
    print("\nüéØ Testing promotion thresholds...")
    
    # Item 1: Access once (no promotion)
    await cache.retrieve(items[0], ci_id='ci_test')
    candidates = cache.get_promotion_candidates()
    print(f"   Item 0 (1 access): {len(candidates)} promotion candidates")
    
    # Item 2: Access twice (should promote)
    await cache.retrieve(items[1], ci_id='ci_test')
    await cache.retrieve(items[1], ci_id='ci_test2')
    candidates = cache.get_promotion_candidates()
    print(f"   Item 1 (2 accesses): {len(candidates)} promotion candidates")
    
    # Item 3: Access three times (definitely promote)
    for j in range(3):
        await cache.retrieve(items[2], ci_id=f'ci_{j}')
    candidates = cache.get_promotion_candidates()
    print(f"   Item 2 (3 accesses): {len(candidates)} promotion candidates")
    
    # Check which items are marked for promotion
    print("\nüìã Promotion candidates:")
    for candidate_key in candidates:
        entry = cache.cache.get(candidate_key)
        if entry:
            print(f"   ‚úì {candidate_key[:8]}... accessed {entry.access_count} times")
    
    # Test cache analysis
    analysis = cache.analyze_patterns()
    print(f"\nüìä Cache Analysis:")
    print(f"   Total entries: {analysis['total_entries']}")
    print(f"   Total accesses: {analysis['total_accesses']}")
    print(f"   Unique CIs: {analysis['unique_cis']}")
    print(f"   Avg accesses per entry: {analysis['avg_accesses_per_entry']:.1f}")
    
    return len(candidates) >= 2  # At least 2 items should be promoted


async def test_synthesis_with_contradictions():
    """Test memory synthesis with contradictory information."""
    print("\nüß© MEMORY SYNTHESIS TEST")
    print("-"*40)
    
    from engram.core.storage.universal_encoder import MemorySynthesizer, MemoryResponse
    
    # Create memories with contradictions
    print("\nüìù Creating contradictory memories...")
    memories = [
        MemoryResponse(
            content={"fact": "The capital is Paris", "country": "France", "year": 2024},
            source_backend="sql_db",
            retrieval_time=0.02,
            confidence=0.95,
            metadata={"source": "database"}
        ),
        MemoryResponse(
            content={"fact": "The capital is Paris", "country": "France", "year": 2023},
            source_backend="document_db",
            retrieval_time=0.01,
            confidence=0.90,
            metadata={"source": "document"}
        ),
        MemoryResponse(
            content={"fact": "The capital is Lyon", "country": "France", "year": 2024},
            source_backend="cache_db",
            retrieval_time=0.005,
            confidence=0.70,
            metadata={"source": "cache"}
        )
    ]
    
    for mem in memories:
        print(f"   {mem.source_backend}: '{mem.content['fact']}' (confidence: {mem.confidence})")
    
    # Synthesize
    print("\nüîÄ Synthesizing memories...")
    synthesizer = MemorySynthesizer()
    result = synthesizer.synthesize(memories, query="France capital")
    
    print(f"   Status: {result.get('status', 'unknown')}")
    print(f"   Sources used: {len(result.get('sources', []))}")
    
    if 'contradictions' in result:
        print(f"   ‚ö†Ô∏è Contradictions detected: {len(result['contradictions'])}")
        for contradiction in result['contradictions']:
            print(f"      - {contradiction}")
    
    if 'primary_memory' in result:
        primary = result['primary_memory']
        print(f"   Primary memory (highest confidence): {primary.get('fact', 'N/A')}")
    
    if 'synthesis' in result:
        print(f"   Synthesis: {result['synthesis']}")
    
    return 'status' in result


async def test_cognitive_workflows():
    """Test the natural cognitive interfaces."""
    print("\nüß† COGNITIVE WORKFLOWS TEST")
    print("-"*40)
    
    from engram.core.storage.cognitive_workflows import CognitiveWorkflows, ThoughtType
    from engram.core.storage.cache_layer import CacheLayer
    from engram.core.storage.universal_encoder import UniversalEncoder
    
    # Mock backend
    class SimpleBackend:
        def __init__(self):
            self.memories = {}
        
        async def store(self, k, v, **kwargs):
            self.memories[k] = v
            return True
        
        async def retrieve(self, k):
            return self.memories.get(k)
        
        async def search(self, query):
            return []
    
    cache = CacheLayer(max_size=100)
    encoder = UniversalEncoder({'backend': SimpleBackend()})
    workflows = CognitiveWorkflows(cache=cache, encoder=encoder)
    
    print("\nüí≠ Testing thought storage...")
    thoughts = [
        ("ESR system is revolutionary", ThoughtType.INSIGHT),
        ("Memory should be natural", ThoughtType.IDEA),
        ("Store everywhere works", ThoughtType.OBSERVATION)
    ]
    
    stored_keys = []
    for thought, thought_type in thoughts:
        key = await workflows.store_thought(thought, thought_type)
        stored_keys.append(key)
        print(f"   ‚úì {thought_type.value}: '{thought[:30]}...' ‚Üí {key[:8]}...")
    
    print("\nüîç Testing recall...")
    # Test recall_similar
    similar = await workflows.recall_similar("memory system")
    print(f"   recall_similar('memory system'): Found {len(similar) if similar else 0} memories")
    
    # Test build_context
    context = await workflows.build_context("ESR testing")
    print(f"   build_context('ESR testing'): Built context with {len(context.get('relevant_memories', []))} memories")
    
    # Test memory_metabolism
    print("\n‚ôªÔ∏è Testing memory metabolism...")
    consolidated = await workflows.memory_metabolism()
    print(f"   Memory metabolism: {consolidated} memories processed")
    
    return len(stored_keys) == 3


async def run_all_tests():
    """Run all comprehensive tests."""
    tests = [
        ("Store Everywhere", test_store_everywhere_detailed),
        ("Frequency Promotion", test_frequency_promotion_detailed),
        ("Memory Synthesis", test_synthesis_with_contradictions),
        ("Cognitive Workflows", test_cognitive_workflows)
    ]
    
    results = []
    for name, test_func in tests:
        try:
            success = await test_func()
            results.append((name, success))
            print(f"\n{'‚úÖ' if success else '‚ùå'} {name} test {'passed' if success else 'failed'}")
        except Exception as e:
            print(f"\n‚ùå {name} test error: {e}")
            results.append((name, False))
    
    return results


async def main():
    """Main test runner."""
    try:
        # Check imports first
        print("\nüì¶ Verifying imports...")
        from engram.core.storage.cache_layer import CacheLayer
        from engram.core.storage.universal_encoder import UniversalEncoder
        from engram.core.storage.cognitive_workflows import CognitiveWorkflows
        from engram.core.storage.associative_retrieval import AssociativeRetrieval
        from engram.core.storage.unified_interface import ESRMemorySystem, HERMES_AVAILABLE
        print("   ‚úì All core modules imported successfully")
        print(f"   ‚ÑπÔ∏è Hermes available: {HERMES_AVAILABLE}")
        
        # Run all tests
        results = await run_all_tests()
        
        # Summary
        print("\n" + "="*70)
        print("TEST SUMMARY")
        print("="*70)
        
        passed = sum(1 for _, success in results if success)
        total = len(results)
        
        for test_name, success in results:
            status = "‚úÖ PASS" if success else "‚ùå FAIL"
            print(f"{status}: {test_name}")
        
        print(f"\nResults: {passed}/{total} tests passed")
        
        if passed == total:
            print("\n" + "üéâ"*10)
            print("ALL ESR TESTS PASSED!")
            print("üéâ"*10)
            print("\n‚ú® Validated capabilities:")
            print("‚Ä¢ Store in ALL backends simultaneously (no routing)")
            print("‚Ä¢ Frequency-based promotion at exactly 2 accesses")
            print("‚Ä¢ Synthesis handles contradictions gracefully")
            print("‚Ä¢ Natural cognitive interfaces work perfectly")
            print("‚Ä¢ Cache analysis provides insights")
            print("\nüí° The 'store everywhere, synthesize on recall' paradigm is")
            print("   fully operational and ready for integration!")
        
        return passed == total
        
    except Exception as e:
        print(f"\n‚ùå Test suite error: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)