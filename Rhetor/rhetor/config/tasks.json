{
  "code": {
    "role": "code-analysis",
    "options": {
      "temperature": 0.2,
      "max_tokens": 4000,
      "priority": "high"
    }
  },
  "planning": {
    "role": "planning",
    "options": {
      "temperature": 0.7,
      "max_tokens": 4000,
      "priority": "medium"
    }
  },
  "reasoning": {
    "role": "knowledge-synthesis",
    "options": {
      "temperature": 0.5,
      "max_tokens": 4000,
      "priority": "medium"
    }
  },
  "chat": {
    "role": "messaging",
    "options": {
      "temperature": 0.8,
      "max_tokens": 2000,
      "priority": "low"
    }
  },
  "default": {
    "role": "orchestration",
    "options": {
      "temperature": 0.7,
      "max_tokens": 4000,
      "priority": "medium"
    }
  },
  "ergon": {
    "role": "agent-coordination",
    "options": {
      "temperature": 0.7,
      "max_tokens": 4000,
      "priority": "high"
    }
  },
  "hermes": {
    "role": "messaging",
    "options": {
      "temperature": 0.7,
      "max_tokens": 2000,
      "priority": "high"
    }
  },
  "telos": {
    "role": "planning",
    "options": {
      "temperature": 0.7,
      "max_tokens": 4000,
      "priority": "high"
    }
  },
  "engram": {
    "role": "memory",
    "options": {
      "temperature": 0.5,
      "max_tokens": 2000,
      "priority": "high"
    }
  },
  "orchestration": {
    "role": "orchestration",
    "options": {
      "temperature": 0.7,
      "max_tokens": 4000,
      "priority": "high"
    }
  },
  "knowledge-synthesis": {
    "role": "knowledge-synthesis",
    "options": {
      "temperature": 0.6,
      "max_tokens": 4000,
      "priority": "medium"
    }
  },
  "specialist-management": {
    "role": "specialist-management",
    "options": {
      "temperature": 0.5,
      "max_tokens": 3000,
      "priority": "high"
    }
  },
  "workflow-design": {
    "role": "workflow-design",
    "options": {
      "temperature": 0.6,
      "max_tokens": 3000,
      "priority": "medium"
    }
  },
  "learning": {
    "role": "learning",
    "options": {
      "temperature": 0.7,
      "max_tokens": 3000,
      "priority": "medium"
    }
  }
}