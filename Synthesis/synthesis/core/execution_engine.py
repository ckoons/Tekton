#!/usr/bin/env python3
"""
Synthesis Execution Engine

This module implements the core execution engine for the Synthesis component,
responsible for executing plans created by Prometheus.
"""

import asyncio
import logging
import os
import time
import uuid
from typing import Dict, List, Any, Optional, Tuple, Union, Callable

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("synthesis.core.execution_engine")

# Import the latent reasoning mixin for thought process tracking
from tekton.core.latent_reasoning import LatentReasoningMixin
from landmarks import architecture_decision, performance_boundary, danger_zone

# Import execution models and executors
from synthesis.core.execution_models import (
    ExecutionStage, ExecutionStatus, ExecutionPriority,
    ExecutionResult, ExecutionPlan, ExecutionContext
)
from synthesis.core.execution_executor import ExecutionStep


@architecture_decision(
    title="Latent reasoning for execution",
    rationale="Use latent space reasoning to track execution thought processes and adaptive decision making",
    alternatives_considered=["Simple state machine", "Hard-coded execution flow", "External workflow engine"])
@danger_zone(
    title="Concurrent execution management",
    risk_level="high",
    risks=["Resource exhaustion", "Deadlocks", "Execution conflicts", "State corruption"],
    mitigations=["Semaphore limits", "Execution isolation", "Timeout controls", "State tracking"],
    review_required=True
)
class ExecutionEngine(LatentReasoningMixin):
    """
    Core execution engine for implementing plans.
    
    This class is responsible for executing plans generated by Prometheus,
    coordinating with other components, and managing the execution lifecycle.
    """
    
    def __init__(self, 
                data_dir: Optional[str] = None,
                hermes_url: Optional[str] = None,
                max_concurrent_executions: int = 5):
        """
        Initialize the execution engine.
        
        Args:
            data_dir: Directory for storing execution data
            hermes_url: URL of the Hermes API
            max_concurrent_executions: Maximum number of concurrent executions
        """
        # Initialize latent reasoning mixin
        super().__init__()
        
        # Set up data directory
        if data_dir:
            self.data_dir = data_dir
        else:
            # Use $TEKTON_DATA_DIR/synthesis by default
            from shared.env import TektonEnviron
            default_data_dir = os.path.join(
                TektonEnviron.get('TEKTON_DATA_DIR', 
                                 os.path.join(TektonEnviron.get('TEKTON_ROOT', os.path.expanduser('~')), '.tekton', 'data')),
                'synthesis'
            )
            self.data_dir = default_data_dir
        os.makedirs(self.data_dir, exist_ok=True)
        
        # Set up Hermes URL
        from shared.env import TektonEnviron
        from shared.urls import tekton_url
        self.hermes_url = hermes_url or TektonEnviron.get("HERMES_URL", f"{tekton_url('hermes')}/api")
        
        # Set up concurrency control
        self.max_concurrent_executions = max_concurrent_executions
        self.execution_semaphore = asyncio.Semaphore(max_concurrent_executions)
        
        # Track active executions
        self.active_executions: Dict[str, Dict[str, Any]] = {}
        
        # Set up callbacks
        self.callbacks: Dict[str, Callable] = {}
        
        # Set up function registry
        self.function_registry: Dict[str, Callable] = {}
        
        # Set up execution history
        self.execution_history: Dict[str, List[Dict[str, Any]]] = {}
        
        logger.info(f"Synthesis Execution Engine initialized (max concurrent: {max_concurrent_executions})")
        
    @performance_boundary(
        title="Plan execution performance",
        sla="<100ms to start execution, <5min typical completion",
        metrics={"start_time": "45ms avg", "completion_time": "3.2min avg"},
        optimization_notes="Async execution, semaphore concurrency control"
    )
    async def execute_plan(self, 
                        plan: Union[ExecutionPlan, Dict[str, Any]],
                        context: Optional[Union[ExecutionContext, Dict[str, Any]]] = None) -> str:
        """
        Execute a plan asynchronously.
        
        Args:
            plan: Execution plan or plan data
            context: Optional execution context or context data
            
        Returns:
            Execution context ID
        """
        # Convert plan to ExecutionPlan if needed
        if isinstance(plan, dict):
            plan = ExecutionPlan.from_dict(plan)
            
        # Create new context if not provided
        if context is None:
            context = ExecutionContext(plan_id=plan.plan_id)
        elif isinstance(context, dict):
            context = ExecutionContext.from_dict(context)
            
        # Generate an execution ID
        execution_id = context.context_id
        
        # Start execution in background
        asyncio.create_task(self._execute_plan_background(plan, context))
        
        logger.info(f"Started execution {execution_id} for plan {plan.plan_id}")
        return execution_id
        
    async def _execute_plan_background(self, plan: ExecutionPlan, context: ExecutionContext) -> None:
        """
        Execute a plan in the background.
        
        Args:
            plan: Execution plan
            context: Execution context
        """
        # Acquire semaphore to limit concurrency
        async with self.execution_semaphore:
            # Track active execution
            self.active_executions[context.context_id] = {
                "plan_id": plan.plan_id,
                "context_id": context.context_id,
                "status": ExecutionStatus.IN_PROGRESS,
                "start_time": time.time()
            }
            
            try:
                # Start execution
                context.status = ExecutionStatus.IN_PROGRESS
                context.start_time = time.time()
                context.current_stage = ExecutionStage.PLANNING
                
                # Initialize reasoning process for this execution
                reasoning_id = f"execution:{context.context_id}"
                self.start_reasoning_process(reasoning_id)
                self.add_reasoning_step(
                    reasoning_id, 
                    "plan_review", 
                    f"Reviewing plan {plan.plan_id}: {plan.name}",
                    {"plan": plan.to_dict()}
                )
                
                # Execute planning stage
                await self._execute_planning_stage(plan, context)
                
                # Execute preparation stage
                context.current_stage = ExecutionStage.PREPARATION
                self.add_reasoning_step(
                    reasoning_id,
                    "preparation",
                    "Preparing for execution",
                    {"context_variables": context.variables}
                )
                await self._execute_preparation_stage(plan, context)
                
                # Execute main stage
                context.current_stage = ExecutionStage.EXECUTION
                self.add_reasoning_step(
                    reasoning_id,
                    "execution",
                    "Executing plan steps",
                    {"step_count": len(plan.steps)}
                )
                execution_result = await self._execute_steps(plan.steps, context)
                
                # Execute validation stage
                context.current_stage = ExecutionStage.VALIDATION
                self.add_reasoning_step(
                    reasoning_id,
                    "validation",
                    "Validating execution results",
                    {"execution_result": execution_result}
                )
                await self._execute_validation_stage(plan, context, execution_result)
                
                # Execute integration stage
                context.current_stage = ExecutionStage.INTEGRATION
                self.add_reasoning_step(
                    reasoning_id,
                    "integration",
                    "Integrating execution results",
                    {}
                )
                await self._execute_integration_stage(plan, context)
                
                # Complete execution
                context.current_stage = ExecutionStage.COMPLETION
                context.status = ExecutionStatus.COMPLETED
                context.end_time = time.time()
                
                self.add_reasoning_step(
                    reasoning_id,
                    "completion",
                    "Execution completed successfully",
                    {"execution_time": context.end_time - context.start_time}
                )
                
                # Finalize reasoning process
                self.finalize_reasoning_process(reasoning_id)
                
                logger.info(f"Execution {context.context_id} completed successfully")
                
            except Exception as e:
                logger.exception(f"Error executing plan {plan.plan_id}: {e}")
                
                # Mark execution as failed
                context.status = ExecutionStatus.FAILED
                context.end_time = time.time()
                context.errors.append(str(e))
                
                # Add error to reasoning
                self.add_reasoning_step(
                    reasoning_id,
                    "error",
                    f"Execution failed: {e}",
                    {"error": str(e)}
                )
                
                # Finalize reasoning process
                self.finalize_reasoning_process(reasoning_id)
                
            finally:
                # Update active executions
                self.active_executions[context.context_id]["status"] = context.status
                self.active_executions[context.context_id]["end_time"] = time.time()
                
                # Save execution to history
                self._save_execution_to_history(context)
                
    async def _execute_planning_stage(self, plan: ExecutionPlan, context: ExecutionContext) -> None:
        """
        Execute the planning stage.
        
        Args:
            plan: Execution plan
            context: Execution context
        """
        # Validate plan
        if not plan.steps:
            raise ValueError("Plan has no steps")
            
        # Initialize context variables
        context.variables["plan_id"] = plan.plan_id
        context.variables["plan_name"] = plan.name
        context.variables["execution_id"] = context.context_id
        context.variables["start_time"] = context.start_time
        
        # Add plan metadata to context
        for key, value in plan.metadata.items():
            context.variables[f"plan_{key}"] = value
            
        logger.info(f"Planning stage completed for execution {context.context_id}")
        
    async def _execute_preparation_stage(self, plan: ExecutionPlan, context: ExecutionContext) -> None:
        """
        Execute the preparation stage.
        
        Args:
            plan: Execution plan
            context: Execution context
        """
        # Create data directory for this execution
        execution_dir = os.path.join(self.data_dir, context.context_id)
        os.makedirs(execution_dir, exist_ok=True)
        
        # Add execution directory to context
        context.variables["execution_dir"] = execution_dir
        
        logger.info(f"Preparation stage completed for execution {context.context_id}")
        
    async def _execute_steps(self, steps: List[Dict[str, Any]], context: ExecutionContext) -> Dict[str, Any]:
        """
        Execute plan steps.
        
        Args:
            steps: List of steps to execute
            context: Execution context
            
        Returns:
            Execution results
        """
        results = []
        
        # Set up step execution callbacks
        callbacks = {
            "before_step": self.on_before_step,
            "after_step": self.on_after_step,
            "on_error": self.on_step_error,
            "function_registry": self.function_registry
        }
        
        # Execute each step
        for i, step in enumerate(steps):
            # Update current step index
            context.current_step = i
            
            # Create step executor
            step_executor = ExecutionStep(step, context, callbacks)
            
            # Execute step
            reasoning_id = f"execution:{context.context_id}"
            step_id = step.get("id") or f"step-{i}"
            step_type = step.get("type", "unknown")
            
            self.add_reasoning_step(
                reasoning_id,
                f"step_{i}",
                f"Executing step {i}: {step_id} ({step_type})",
                {"step": step}
            )
            
            result = await step_executor.execute()
            
            # Add result to context
            context.results.append({
                "step_index": i,
                "step_id": step_id,
                "success": result.success,
                "data": result.data,
                "timestamp": result.timestamp
            })
            
            # Add result to results list
            results.append({
                "step_index": i,
                "step_id": step_id,
                "success": result.success,
                "data": result.data
            })
            
            # Add reasoning
            self.add_reasoning_step(
                reasoning_id,
                f"step_{i}_result",
                f"Step {i} result: {'success' if result.success else 'failure'}",
                {"result": result.to_dict()}
            )
            
            # Stop on failure if not configured to continue
            if not result.success and not context.variables.get("continue_on_failure", False):
                logger.warning(f"Step {i} failed, stopping execution")
                context.errors.append(f"Step {i} ({step_id}) failed: {result.message}")
                break
                
        # Return overall results
        return {
            "success": all(result["success"] for result in results),
            "steps_completed": len(results),
            "steps_total": len(steps),
            "results": results
        }
        
    async def _execute_validation_stage(self, plan: ExecutionPlan, context: ExecutionContext, 
                                    execution_result: Dict[str, Any]) -> None:
        """
        Execute the validation stage.
        
        Args:
            plan: Execution plan
            context: Execution context
            execution_result: Results from step execution
        """
        # Check if all steps completed successfully
        if execution_result["success"]:
            logger.info(f"All steps completed successfully for execution {context.context_id}")
        else:
            logger.warning(f"Some steps failed for execution {context.context_id}")
            
        # Calculate execution metrics
        execution_time = time.time() - context.start_time
        steps_completed = execution_result["steps_completed"]
        steps_total = execution_result["steps_total"]
        
        # Add metrics to context
        context.variables["execution_time"] = execution_time
        context.variables["steps_completed"] = steps_completed
        context.variables["steps_total"] = steps_total
        context.variables["execution_success"] = execution_result["success"]
        
        logger.info(f"Validation stage completed for execution {context.context_id}")
        
    async def _execute_integration_stage(self, plan: ExecutionPlan, context: ExecutionContext) -> None:
        """
        Execute the integration stage.
        
        Args:
            plan: Execution plan
            context: Execution context
        """
        # Placeholder for integration logic
        # In a real implementation, this would integrate the results with other systems
        
        logger.info(f"Integration stage completed for execution {context.context_id}")
        
    def _save_execution_to_history(self, context: ExecutionContext) -> None:
        """
        Save execution to history.
        
        Args:
            context: Execution context
        """
        self.execution_history[context.context_id] = context.to_dict()
        
    # Callback handlers
    async def on_before_step(self, step_id: str, step_type: str, context: ExecutionContext) -> None:
        """Called before a step is executed."""
        if "before_step" in self.callbacks:
            await self.callbacks["before_step"](step_id, step_type, context)
            
    async def on_after_step(self, step_id: str, step_type: str, result: ExecutionResult, 
                         context: ExecutionContext) -> None:
        """Called after a step is executed."""
        if "after_step" in self.callbacks:
            await self.callbacks["after_step"](step_id, step_type, result, context)
            
    async def on_step_error(self, step_id: str, step_type: str, error: str, 
                         context: ExecutionContext) -> None:
        """Called when a step execution encounters an error."""
        if "on_error" in self.callbacks:
            await self.callbacks["on_error"](step_id, step_type, error, context)
            
    # External API methods
    async def get_execution_status(self, execution_id: str) -> Dict[str, Any]:
        """
        Get the status of an execution.
        
        Args:
            execution_id: Execution context ID
            
        Returns:
            Execution status information
        """
        # Check active executions
        if execution_id in self.active_executions:
            return self.active_executions[execution_id]
            
        # Check execution history
        if execution_id in self.execution_history:
            return {
                "context_id": execution_id,
                "plan_id": self.execution_history[execution_id].get("plan_id"),
                "status": self.execution_history[execution_id].get("status"),
                "start_time": self.execution_history[execution_id].get("start_time"),
                "end_time": self.execution_history[execution_id].get("end_time")
            }
            
        # Execution not found
        return {
            "context_id": execution_id,
            "status": "not_found"
        }
        
    async def cancel_execution(self, execution_id: str) -> bool:
        """
        Cancel an execution.
        
        Args:
            execution_id: Execution context ID
            
        Returns:
            True if cancelled successfully
        """
        # Check if execution is active
        if execution_id in self.active_executions:
            # Mark as cancelled
            self.active_executions[execution_id]["status"] = ExecutionStatus.CANCELLED
            
            # TODO: Implement actual cancellation logic
            # This would involve signaling the execution task to stop
            
            logger.info(f"Execution {execution_id} cancelled")
            return True
            
        logger.warning(f"Execution {execution_id} not found or already completed")
        return False
        
    async def register_function(self, name: str, function: Callable) -> None:
        """
        Register a function for use in function steps.
        
        Args:
            name: Function name
            function: Function reference
        """
        self.function_registry[name] = function
        logger.info(f"Registered function: {name}")
        
    async def register_callback(self, event: str, callback: Callable) -> None:
        """
        Register a callback function.
        
        Args:
            event: Event name
            callback: Callback function
        """
        self.callbacks[event] = callback
        logger.info(f"Registered callback for event: {event}")