#!/usr/bin/env python3
"""
AI Message Service - One Queue Per AI

Casey's design:
- ONE queue per AI
- ONE connection per AI
- Simple request/response tracking with IDs
- Consumers (team-chat, direct chat) just send and collect

This is THE central service for all AI communication in Tekton.
"""

import asyncio
import json
import time
import uuid
from typing import Dict, Optional, Any, List
from dataclasses import dataclass, field
from collections import defaultdict
import logging

logger = logging.getLogger(__name__)


@dataclass
class Message:
    """Message in an AI's queue"""
    id: str
    request: str
    response: Optional[str] = None
    status: str = "pending"  # pending, sent, responded, error
    error: Optional[str] = None
    created_at: float = field(default_factory=time.time)
    sent_at: Optional[float] = None
    responded_at: Optional[float] = None


class AIMessageService:
    """
    Central message service for all AI communication.
    Maintains one queue per AI, handles all request/response routing.
    """
    
    def __init__(self, debug: bool = False):
        self.debug = debug
        # One queue per AI
        self._queues: Dict[str, Dict[str, Message]] = defaultdict(dict)  # ai_id -> {msg_id -> Message}
        # Track connection info per AI
        self._ai_connections: Dict[str, tuple] = {}  # ai_id -> (host, port)
        # Single connection per AI (when we implement connection pooling)
        self._connections: Dict[str, Any] = {}  # ai_id -> connection object
        
    def send_request(self, ai_id: str, request: str) -> str:
        """
        Queue a request for an AI. Returns message ID for tracking.
        This is the primary interface for all consumers.
        """
        msg_id = str(uuid.uuid4())
        message = Message(id=msg_id, request=request)
        
        # Add to AI's queue
        self._queues[ai_id][msg_id] = message
        
        if self.debug:
            logger.info(f"Queued {msg_id} for {ai_id}: {request[:50]}...")
            
        return msg_id
        
    def collect_response(self, ai_id: str, msg_id: str, timeout: float = 30.0) -> Optional[Dict[str, Any]]:
        """
        Collect a specific response by AI and message ID.
        Returns None if not ready yet or timeout.
        """
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            if ai_id in self._queues and msg_id in self._queues[ai_id]:
                message = self._queues[ai_id][msg_id]
                
                if message.status == "responded":
                    return {
                        "success": True,
                        "response": message.response,
                        "elapsed_time": message.responded_at - message.created_at
                    }
                elif message.status == "error":
                    return {
                        "success": False,
                        "error": message.error or "Unknown error",
                        "elapsed_time": time.time() - message.created_at
                    }
                    
            # Not ready yet, wait a bit
            time.sleep(0.1)
            
        # Timeout
        return None
        
    def collect_all_responses(self, ai_id: str, msg_ids: List[str], 
                            timeout: float = 30.0) -> Dict[str, Dict[str, Any]]:
        """
        Collect multiple responses for an AI.
        Useful for batch operations.
        """
        responses = {}
        start_time = time.time()
        remaining = set(msg_ids)
        
        while remaining and time.time() - start_time < timeout:
            for msg_id in list(remaining):
                response = self.collect_response(ai_id, msg_id, timeout=0.1)
                if response:
                    responses[msg_id] = response
                    remaining.remove(msg_id)
                    
            if remaining:
                time.sleep(0.1)
                
        return responses
        
    def register_ai(self, ai_id: str, host: str, port: int):
        """Register AI connection info. Called during discovery."""
        self._ai_connections[ai_id] = (host, port)
        
    async def process_queues(self):
        """
        Process all pending messages in all queues.
        This is called periodically or after adding messages.
        """
        # Process each AI's queue
        for ai_id, queue in self._queues.items():
            if ai_id not in self._ai_connections:
                continue
                
            # Get pending messages for this AI
            pending = [msg for msg in queue.values() if msg.status == "pending"]
            if not pending:
                continue
                
            # Process this AI's pending messages
            host, port = self._ai_connections[ai_id]
            for message in pending:
                await self._send_to_ai(ai_id, host, port, message)
                
    async def _send_to_ai(self, ai_id: str, host: str, port: int, message: Message):
        """Send a single message to an AI and update its status."""
        try:
            # Mark as sent
            message.status = "sent"
            message.sent_at = time.time()
            
            # Connect and send (reuse connection if exists)
            reader, writer = await asyncio.open_connection(host, port)
            
            # Send request
            request_data = {
                "type": "chat",
                "content": message.request,
                "message_id": message.id
            }
            
            writer.write(json.dumps(request_data).encode('utf-8') + b'\n')
            await writer.drain()
            
            # Read response
            response_data = await asyncio.wait_for(reader.readline(), timeout=10.0)
            
            if response_data:
                response = json.loads(response_data.decode('utf-8').strip())
                message.response = response.get('response', response.get('content', str(response)))
                message.status = "responded"
                message.responded_at = time.time()
            else:
                message.status = "error"
                message.error = "No response received"
                
            # Close connection (later we'll pool these)
            writer.close()
            await writer.wait_closed()
            
        except asyncio.TimeoutError:
            message.status = "error"
            message.error = "Timeout waiting for response"
        except Exception as e:
            message.status = "error"
            message.error = str(e)
            if self.debug:
                logger.error(f"Error sending to {ai_id}: {e}")
                
    def get_queue_status(self, ai_id: str) -> Dict[str, int]:
        """Get status counts for an AI's queue."""
        if ai_id not in self._queues:
            return {"pending": 0, "sent": 0, "responded": 0, "error": 0}
            
        queue = self._queues[ai_id]
        status_counts = defaultdict(int)
        for message in queue.values():
            status_counts[message.status] += 1
            
        return dict(status_counts)
        
    def clear_old_messages(self, ai_id: str, max_age: float = 3600):
        """Clear messages older than max_age seconds."""
        if ai_id not in self._queues:
            return
            
        current_time = time.time()
        queue = self._queues[ai_id]
        old_ids = [
            msg_id for msg_id, msg in queue.items()
            if current_time - msg.created_at > max_age
        ]
        
        for msg_id in old_ids:
            del queue[msg_id]
            
    # Convenience methods for team chat
            
    def broadcast_request(self, request: str, ai_ids: List[str]) -> Dict[str, str]:
        """
        Send same request to multiple AIs.
        Returns {ai_id: msg_id} for tracking.
        """
        msg_ids = {}
        for ai_id in ai_ids:
            msg_ids[ai_id] = self.send_request(ai_id, request)
        return msg_ids
        
    async def collect_broadcast_responses(self, msg_ids: Dict[str, str], 
                                        timeout: float = 30.0):
        """
        Collect responses from a broadcast.
        Yields responses as they arrive.
        """
        start_time = time.time()
        remaining = set(msg_ids.keys())
        
        if self.debug:
            logger.info(f"Collecting responses for {len(remaining)} AIs")
        
        while remaining and time.time() - start_time < timeout:
            for ai_id in list(remaining):
                msg_id = msg_ids[ai_id]
                response = self.collect_response(ai_id, msg_id, timeout=0.1)
                
                if response:
                    remaining.remove(ai_id)
                    yield ai_id, response
                    
            if remaining:
                await asyncio.sleep(0.1)


# Global instance
_service = None

def get_ai_message_service(debug: bool = False) -> AIMessageService:
    """Get the global AI message service instance."""
    global _service
    if _service is None:
        _service = AIMessageService(debug=debug)
    return _service