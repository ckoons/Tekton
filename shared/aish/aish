#!/usr/bin/env python3
"""
aish - The AI Shell
Main entry point for the AI shell interpreter.
"""

import sys
import os
import argparse
from pathlib import Path

# Try to import landmarks if available
try:
    from landmarks import architecture_decision, integration_point, api_contract, state_checkpoint
except ImportError:
    # Landmarks not available, create no-op decorators
    def architecture_decision(**kwargs):
        def decorator(func):
            return func
        return decorator
    
    def integration_point(**kwargs):
        def decorator(func):
            return func
        return decorator
    
    def api_contract(**kwargs):
        def decorator(func):
            return func
        return decorator
    
    def state_checkpoint(**kwargs):
        def decorator(func):
            return func
        return decorator


# Get the real path of the script (follows symlinks)
script_path = Path(__file__).resolve()
aish_root = script_path.parent
src_path = aish_root / 'src'

# Add src to path
sys.path.insert(0, str(src_path))

# Add parent paths to find shared module (we're in $TEKTON_ROOT/shared/aish)
tekton_root_for_import = aish_root.parent.parent  # Go up to $TEKTON_ROOT
if tekton_root_for_import.exists() and (tekton_root_for_import / 'shared').exists():
    sys.path.insert(0, str(tekton_root_for_import))

# Perform TektonEnvironLock.load() to ensure TektonEnviron is available
from shared.env import TektonEnvironLock, TektonEnviron
TektonEnvironLock.load() 

# Trust TEKTON_ROOT from environment
env_tekton_root = TektonEnviron.get('TEKTON_ROOT')
if not env_tekton_root:
    print(f"Error: TEKTON_ROOT environment variable not set")
    print(f"Please set TEKTON_ROOT to your Tekton installation directory")
    sys.exit(1)

tekton_root = Path(env_tekton_root)

# Verify that aish exists at the expected location
expected_aish = tekton_root / 'shared' / 'aish' / 'aish'
if not expected_aish.exists():
    print(f"Error: aish not found at expected location")
    print(f"  TEKTON_ROOT: {tekton_root}")
    print(f"  Expected aish at: {expected_aish}")
    print(f"  Please ensure TEKTON_ROOT points to a valid Tekton installation")
    sys.exit(1)

# Add tekton_root to path for imports
if tekton_root.exists() and (tekton_root / 'shared').exists():
    sys.path.insert(0, str(tekton_root))

from core.shell import AIShell
from core.version import __version__

# Clean up routes from previous session only if this is the first aish command
# (to avoid deleting routes mid-session)
tekton_root_path = Path(tekton_root)
routes_file = tekton_root_path / '.tekton' / 'aish' / 'routes.json'
session_marker = tekton_root_path / '.tekton' / 'aish' / '.session_active'

# If no session marker exists, this is a new session - clean up old routes
if not session_marker.exists():
    if routes_file.exists():
        routes_file.unlink()
    # Create session marker
    session_marker.parent.mkdir(parents=True, exist_ok=True)
    session_marker.touch()

# Start MCP server if not disabled
if not TektonEnviron.get('AISH_NO_MCP'):
    try:
        # Check if MCP server is already running
        import socket
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        mcp_port = int(TektonEnviron.get("AISH_MCP_PORT", "3100"))
        result = sock.connect_ex(('localhost', mcp_port))
        sock.close()
        
        if result != 0:  # Port not in use, start MCP server
            # Use subprocess to start MCP server
            import subprocess
            import atexit
            
            mcp_script = aish_root / 'aish-mcp'
            if mcp_script.exists():
                # Start MCP server as a separate process
                env = os.environ.copy()
                env['TEKTON_ROOT'] = str(tekton_root)
                
                mcp_process = subprocess.Popen(
                    [sys.executable, str(mcp_script)],
                    env=env,
                    stdout=subprocess.DEVNULL if not TektonEnviron.get('AISH_DEBUG_MCP') else None,
                    stderr=subprocess.DEVNULL if not TektonEnviron.get('AISH_DEBUG_MCP') else None,
                    start_new_session=True  # Detach from parent
                )
                
                # Don't register cleanup - let it run independently
                # atexit.register(lambda: mcp_process.terminate() if mcp_process.poll() is None else None)
                
                if TektonEnviron.get('AISH_DEBUG_MCP'):
                    print(f"[DEBUG] Started MCP server process PID: {mcp_process.pid}", file=sys.stderr)
                
                # Give it time to start
                import time
                time.sleep(1)
            else:
                print(f"Warning: MCP script not found at {mcp_script}", file=sys.stderr)
        else:
            if TektonEnviron.get('AISH_DEBUG_MCP'):
                print(f"[DEBUG] MCP server already running on port {mcp_port}", file=sys.stderr)
    except Exception as e:
        # Don't fail if MCP can't start - aish should still work
        print(f"Warning: Could not start MCP server: {e}", file=sys.stderr)
        if TektonEnviron.get('AISH_DEBUG_MCP'):
            import traceback
            traceback.print_exc(file=sys.stderr)


@integration_point(
    title="Command Type Dispatch Router",
    description="Routes commands to appropriate handlers based on type",
    target_component="command_handlers",
    protocol="function_call",
    data_flow="command_type → import handler → execute command",
    integration_date="2025-01-18"
)
def _dispatch_command(command_type, args, shell):
    """Dispatch command to appropriate handler based on type."""
    if command_type == 'forward':
        from commands.forward import handle_forward_command
        return handle_forward_command(args.message or [])
    elif command_type == 'unforward':
        from commands.forward import handle_unforward_command
        return handle_unforward_command(args.message or [])
    elif command_type == 'prompt':
        from commands.prompt import handle_prompt_command
        return handle_prompt_command(args.message or [])
    elif command_type == 'purpose':
        from commands.purpose import handle_purpose_command
        return handle_purpose_command(args.message or [])
    elif command_type == 'terma':
        from commands.terma import handle_terma_command
        return handle_terma_command(args.message)
    elif command_type == 'review':
        from commands.review import handle_command as handle_review_command
        return handle_review_command(args.message or [])
    elif command_type == 'project':
        from commands.project import handle_project_command
        return handle_project_command(args.message or [])
    # Claude Code IDE Command Integration - CI tooling
    # These commands provide Companion Intelligences with IDE-like capabilities
    # to eliminate guessing and save ~40% context during development.
    elif command_type == 'introspect':
        from commands.introspect import introspect_command
        result = introspect_command(args.message or [], shell)
        print(result)
        return True
    elif command_type == 'context':
        from commands.context import context_command
        result = context_command(args.message or [], shell)
        print(result)
        return True
    elif command_type == 'explain':
        from commands.explain import explain_command
        result = explain_command(args.message or [], shell)
        print(result)
        return True
    elif command_type == 'route':
        from commands.route import handle_route_command
        # Let route command handle its own argument parsing
        return handle_route_command()
    elif command_type == 'test':
        from commands.test import handle_test_command
        return handle_test_command(args.message or [])
    elif command_type == 'alias':
        from commands.alias import handle_alias_command
        return handle_alias_command(args.message or [])
    elif command_type == 'inbox':
        from commands.inbox import handle_inbox_command
        return handle_inbox_command(args.message or [])
    elif command_type == 'ci-tool':
        from shared.ci_tools.commands import handle_ci_tool_command
        return handle_ci_tool_command(args.message or [])
    elif command_type == 'ci-terminal':
        from shared.ci_tools.commands import handle_ci_terminal_command
        return handle_ci_terminal_command(args.message or [])
    elif command_type == 'sundown':
        from commands.sundown import handle_sundown_command
        return handle_sundown_command(['sundown'] + (args.message or []))
    elif command_type == 'sunrise':
        from commands.sundown import handle_sunrise_command
        return handle_sunrise_command(['sunrise'] + (args.message or []))
    return False


@api_contract(
    title="AI Message Input Collection",
    description="Collects input with priority: args > piped stdin > interactive",
    endpoint="internal",
    method="function",
    request_schema={"args": "argparse.Namespace", "component": "string"},
    response_schema={"input_data": "string"},
    performance_requirements="<10ms for args, <100ms for stdin"
)
def _collect_ai_input(args, component):
    """Collect input for AI from various sources."""
    # Get input from message args first, then stdin, then interactive
    if args.message:
        # Message provided as arguments - this takes priority
        input_data = ' '.join(args.message).strip()
        if args.debug:
            print(f"[DEBUG] Using message args: {args.message}")
            print(f"[DEBUG] Joined as: '{input_data}'")
    elif not sys.stdin.isatty():
        # Data might be piped in
        # Try to read with a very short timeout to avoid hanging
        import select
        if select.select([sys.stdin], [], [], 0.0)[0]:
            input_data = sys.stdin.read().strip()
            if args.debug:
                print(f"[DEBUG] Got piped input: '{input_data}'")
        else:
            # No data in pipe, treat as interactive
            print(f"[aish] Entering interactive mode with {component}")
            print("Type your message and press Ctrl+D when done:")
            input_data = sys.stdin.read().strip()
    else:
        # Interactive mode with specific AI
        print(f"[aish] Entering interactive mode with {component}")
        print("Type your message and press Ctrl+D when done:")
        input_data = sys.stdin.read().strip()
    
    return input_data


@integration_point(
    title="AI Communication Handler",
    description="Routes messages to team-chat or individual AIs",
    target_component="ai_shell",
    protocol="internal_api",
    data_flow="command → shell.send_to_ai or shell.broadcast_message",
    integration_date="2025-01-18"
)
def _handle_ai_command(args, shell, ai_names):
    """Handle command directed at a specific AI."""
    component = args.ai_or_script.lower()
    
    # Special handling for terma commands (keeps existing terma subcommands working)
    if component == 'terma':
        _dispatch_command('terma', args, shell)
        return
    
    # Check for help command
    if args.message and args.message[0] == "help":
        print(f"Usage: aish {component} [message]")
        tekton_root = TektonEnviron.get('TEKTON_ROOT', '/Users/cskoons/projects/github/Tekton')
        print(f"AI Training: {tekton_root}/MetaData/TektonDocumentation/AITraining/{component}/")
        print(f"User Guides: {tekton_root}/MetaData/TektonDocumentation/UserGuides/{component}/")
        return
    
    # Collect input from various sources
    input_data = _collect_ai_input(args, component)
    
    # Check if we actually have data
    if not input_data:
        print(f"aish: No message provided for {component}", file=sys.stderr)
        sys.exit(1)
    
    # Use unified sender for all CI types
    sys.path.insert(0, str(src_path))
    
    if component == 'team-chat':
        # Team chat needs special handling - broadcast to all Greek Chorus AIs
        from core.broadcast_client import broadcast_to_cis
        responses = broadcast_to_cis(input_data)
        
        if responses:
            print("Team responses:")
            print("-" * 40)
            for ai_name, content in responses.items():
                print(f"[{ai_name}]: {content}")
            print("-" * 40)
        else:
            print("No responses from team")
    else:
        # Use unified sender for everything else
        from core.unified_sender import send_to_ci
        
        # Determine sender name - try terma first, then fall back to USER
        sender_name = None
        terma_name = TektonEnviron.get('TERMA_TERMINAL_NAME')
        if terma_name and terma_name != 'unnamed':
            sender_name = terma_name
        else:
            # Fall back to system user
            import os
            sender_name = TektonEnviron.get('USER', 'aish')
        
        # Get execute flag from args if available
        execute = False
        delimiter = None
        if hasattr(args, 'execute') and args.execute is not None:
            execute = True
            # Decode escape sequences in delimiter
            try:
                delimiter = args.execute.encode('utf-8').decode('unicode_escape')
            except:
                delimiter = args.execute
        
        send_to_ci(component, input_data, sender_name=sender_name, 
                   execute=execute, delimiter=delimiter)


@architecture_decision(
    title="aish Command Entry Point",
    description="Main orchestration point for all aish commands",
    rationale="Provides unified entry for AI shell, scripts, and individual AI commands",
    alternatives_considered=["Separate binaries per AI", "Menu-driven interface"],
    impacts=["usability", "consistency", "extensibility"],
    decided_by="Casey",
    decision_date="2025-01-18"
)
def main():
    # Special handling for ci-tool which needs its own argument parsing
    if len(sys.argv) > 1 and sys.argv[1] == 'ci-tool':
        from shared.ci_tools.commands import handle_ci_tool_command
        # Pass empty args since ci-tool will read from sys.argv directly
        handle_ci_tool_command([])
        return
    
    # Special handling for ci-terminal which needs its own argument parsing
    if len(sys.argv) > 1 and sys.argv[1] == 'ci-terminal':
        from shared.ci_tools.commands import handle_ci_terminal_command
        # Pass empty args since ci-terminal will read from sys.argv directly
        handle_ci_terminal_command([])
        return
    
    parser = argparse.ArgumentParser(
        description='aish - The AI Shell\n\nProvides AI capabilities in your terminal through the Tekton platform.',
        epilog='''Examples:
  aish                      # Start interactive AI shell
  aish apollo "question"    # Send question to Apollo AI
  echo "data" | aish athena # Pipe data to Athena AI
  aish team-chat "hello"    # Broadcast to all AIs
  aish -l                   # List available AIs
  aish --capture numa "hi"  # Capture output to .tekton/aish/captures/
  aish status               # Show system status
  aish status json          # JSON formatted status
  aish script.ai            # Run AI script file

Available AIs: numa, tekton, prometheus, telos, metis, harmonia,
               synthesis, athena, sophia, noesis, engram, apollo,
               rhetor, penia, hermes, ergon, terma

Environment variables:
  RHETOR_ENDPOINT    # Override default Rhetor endpoint
  AISH_ACTIVE        # Set by aish-proxy when active
  AISH_DEBUG         # Enable debug output
  AISH_NO_MCP        # Disable MCP server startup''',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        'ai_or_script',
        nargs='?',
        help='AI name (apollo, athena, etc.) or script file'
    )
    
    parser.add_argument(
        'message',
        nargs='*',
        help='Message to send to AI'
    )
    
    parser.add_argument(
        '-c', '--command',
        help='Execute a single AI pipeline command and exit'
    )
    
    parser.add_argument(
        '-v', '--version',
        action='version',
        version=f'aish {__version__}'
    )
    
    parser.add_argument(
        '-d', '--debug',
        action='store_true',
        help='Enable debug output'
    )
    
    parser.add_argument(
        '-r', '--rhetor',
        default=None,
        help='Rhetor endpoint (default: TEKTON_RHETOR_PORT env var or http://localhost:8003)'
    )
    
    parser.add_argument(
        '-l', '--list-ais',
        action='store_true',
        help='List available AI specialists and exit'
    )
    
    parser.add_argument(
        '--capture',
        action='store_true',
        help='Capture command output to .tekton/aish/captures/'
    )
    
    parser.add_argument(
        '-x', '--execute',
        nargs='?',
        const='\n',
        default=None,
        help='Execute message with delimiter (default: \\n)'
    )
    
    
    args = parser.parse_args()
    
    # Create shell instance
    shell = AIShell(
        rhetor_endpoint=args.rhetor,
        debug=args.debug,
        capture=args.capture
    )
    
    # Handle general help command
    if args.ai_or_script == "help":
        print("Usage: aish [options] [component] [command/message]")
        tekton_root = TektonEnviron.get('TEKTON_ROOT', '/Users/cskoons/projects/github/Tekton')
        print(f"AI Training: {tekton_root}/MetaData/TektonDocumentation/AITraining/aish/")
        print(f"User Guides: {tekton_root}/MetaData/TektonDocumentation/UserGuides/aish/")
        return
    
    # Handle special commands
    if args.list_ais:
        shell._list_ais()
        return
    
    # Known AI names with their roles (all lowercase for comparison)
    ai_names = ['numa',        # Companion
                'tekton',      # Projects
                'prometheus',  # Planning
                'telos',       # Requirements
                'metis',       # Workflows
                'harmonia',    # Orchestration
                'synthesis',   # Integration
                'athena',      # Knowledge
                'sophia',      # Learning
                'noesis',      # Discovery
                'engram',      # Memory
                'apollo',      # Attention/Prediction
                'rhetor',      # LLM/Prompt/Context
                'penia',       # LLM Cost
                'hermes',      # Messages/Data
                'ergon',       # Agents/Tools/MCP
                'terma',       # Terminal
                'hephaestus',  # UI/DevTools
                'team-chat']   # Broadcast to all
    
    # Handle special commands first
    if args.ai_or_script == 'whoami':
        # Show terminal name from environment
        terminal_name = TektonEnviron.get('TERMA_TERMINAL_NAME', 'Not in terma')
        print(terminal_name)
        return
    
    if args.ai_or_script == 'list':
        # Handle list commands
        if args.message and len(args.message) > 0 and args.message[0] == 'commands':
            # Show command reference
            print("aish Command Reference")
            print("=" * 50)
            print()
            print("CORE COMMANDS:")
            print("  aish                           Show help")
            print("  aish whoami                    Show identity information")
            print("  aish list                      List all CIs (unified registry)")
            print("  aish list type <type>          List CIs by type (terminal/greek/project/tool)")
            print("  aish list json [type]          List CIs in JSON format")
            print("  aish list context              Show context state for all CIs")
            print("  aish list context <ci-name>    Show full context details for specific CI")
            print("  aish list commands             Show this command reference")
            print("  aish <ci-name> \"message\"       Send message to any CI")
            print()
            print("FORWARDING:")
            print("  aish forward <ai> <terminal>   Forward AI messages to terminal")
            print("  aish forward <ai> <terminal> json  Forward as JSON with metadata")
            print("  aish forward list              Show active forwards")
            print("  aish forward remove <ai>       Remove forwarding")
            print("  aish unforward <ai>            Remove forwarding (alternative)")
            print()
            print("PURPOSE:")
            print("  aish purpose                   Get terminal purpose: context for current terminal session")
            print("  aish purpose <name>            Get short form terminal purpose of <name>")
            print("  aish purpose <name> \"roles\"    Set terminal purpose/roles")
            print("  aish purpose \"keyword\"         Search for purpose content (supports CSV: \"coding, test\")")
            print()
            print("PROJECTS:")
            print("  aish project list              List Tekton managed projects with CI info")
            print("  aish project forward <name>    Forward project CI to current terminal")
            print("  aish project forward <name> <terminal>  Forward project CI to specific terminal")
            print("  aish project unforward <name>  Remove project CI forwarding")
            print()
            print("INTELLIGENT ROUTES:")
            print("  aish route name \"review\" numa \"prep\" apollo \"analyze\"  Define named route")
            print("  aish route send \"review\" \"message\"     Send through route")
            print("  aish route list                Show all routes")
            print("  aish route show \"review\"       Show route details")
            print("  aish route remove \"review\"     Remove route")
            print()
            print("TERMINAL:")
            print("  aish terma inbox               Show terminal inbox")
            print("  aish terma send <name> \"msg\"   Send inter-terminal message")
            print("  aish terma broadcast \"msg\"     Broadcast to all terminals")
            print("  aish terma inbox               Show terminal inbox")
            print()
            print("CI TOOLS:")
            print("  aish claude-code \"message\"     Send message to Claude Code")
            print("  aish cursor \"message\"          Send message to Cursor")
            print("  aish continue \"message\"        Send message to Continue")
            print("  aish list type tool            List available CI tools")
            print("  aish forward claude-code <terminal>  Forward tool output to terminal")
            print()
            print("CI TOOLS LIFECYCLE:")
            print("  aish tools list                List available CI tools")
            print("  aish tools status [name]       Show tool/instance status")
            print("  aish tools launch <name>       Launch a tool")
            print("  aish tools terminate <name>    Terminate tool/instance")
            print("  aish tools instances           List running instances")
            print("  aish tools create <name> --type <tool>  Create named instance")
            print("  aish tools capabilities <name> Show tool capabilities")
            print()
            print("SESSION CAPTURE:")
            print("  aish review start              Start recording terminal session")
            print("  aish review stop               Stop recording and save session")
            print("  aish review list               List recent session recordings")
            print()
            print("PRODUCTIVITY:")
            print("  autoprompt start               Keep Claude CI active (default: 2s)")
            print("  autoprompt stop                Stop autoprompt")
            print("  autoprompt status              Check autoprompt status")
            print()
            print("ALIASES:")
            print("  aish alias create tag \"cmd\"    Create reusable command pattern")
            print("  aish alias delete tag          Remove alias")
            print("  aish alias list                Show all aliases")
            print("  aish alias show tag            Show alias details")
            print("  aish tag [args]                Execute alias with optional args")
            print()
            print("SUNDOWN/SUNRISE (Apollo/Rhetor Context Management):")
            print("  aish sundown <ci-name> [reason]  Gracefully preserve CI context")
            print("  aish sunrise <ci-name>            Restore CI with continuity")
            print("  aish sundown status               Show CIs currently in sundown")
            print()
            print("INBOX SYSTEM:")
            print("  aish inbox                     Show message counts (prompt:1 new:3 keep:0)")
            print("  aish inbox send <type> <ci> \"msg\"  Send message to CI's inbox")
            print("  aish inbox show <type>         Display messages in text format")
            print("  aish inbox json <type>         Display messages in JSON format")
            print("  aish inbox get <type>          Get and remove all messages (JSON)")
            print("  aish inbox count <type>        Count messages (returns number only)")
            print("  aish inbox clear <type>        Remove all messages (silent)")
            print("  aish inbox help                Show inbox command help")
            print("  aish inbox training            Show CI training for inbox processing")
            print()
            print("  Inbox types: prompt (urgent), new (regular), keep (saved)")
            print("  Add 'from <ci>' to filter by sender: aish inbox get new from apollo")
            print()
            print("CLAUDE CODE IDE (yes Claude, this really is for you!):")
            print("  aish introspect <class>        See all methods of a class - no more guessing!")
            print("  aish context <file.py>         Show available classes in file scope")
            print("  aish explain \"error msg\"       Get help fixing Python errors")
            print()
            print("  CIs: You're encouraged to use these tools liberally. If you find patterns")
            print("  that could be improved or new commands that would help, please suggest them!")
            print()
            print("STATUS & DEBUG:")
            print("  aish status                    Show forwarding, AIs, and terminal status")
            print("  aish status --json             Machine-readable status output")
            print("  aish status mcp                Check MCP server status")
            print("  aish restart                   Restart MCP server")
            print("  aish logs                      Show MCP server logs")
            print("  aish debug-mcp                 Toggle MCP debug mode")
            print()
            print("TESTING:")
            print("  aish test                      Run all functional tests")
            print("  aish test <suite>              Run specific test suite")
            print("  aish test help                 Show detailed test information")
            print()
            print("ADVANCED:")
            print("  echo \"msg\" | aish <ai>         Pipe input to AI")
            print("  aish <ai1> | aish <ai2>        Chain AI responses")
            print("  aish team-chat \"message\"       Broadcast to all AIs")
            print()
            tekton_root = TektonEnviron.get('TEKTON_ROOT', '/Users/cskoons/projects/github/Tekton')
            print(f"Full documentation: {tekton_root}/MetaData/TektonDocumentation/AITraining/aish/COMMAND_REFERENCE.md")
            return
        else:
            # Use new unified list handler
            sys.path.insert(0, str(src_path))  # Ensure src is in path
            from commands.list import handle_list_command
            handle_list_command(args.message if args.message else [])
            return
    
    if args.ai_or_script == 'forward':
        return _dispatch_command('forward', args, shell)
    
    if args.ai_or_script == 'unforward':
        return _dispatch_command('unforward', args, shell)
    
    if args.ai_or_script == 'prompt':
        return _dispatch_command('prompt', args, shell)
    
    if args.ai_or_script == 'purpose':
        return _dispatch_command('purpose', args, shell)
    
    if args.ai_or_script == 'review':
        return _dispatch_command('review', args, shell)
    
    if args.ai_or_script == 'project':
        return _dispatch_command('project', args, shell)
    
    if args.ai_or_script == 'route':
        return _dispatch_command('route', args, shell)
    
    if args.ai_or_script == 'ci-tool':
        return _dispatch_command('ci-tool', args, shell)
    
    if args.ai_or_script == 'ci-terminal':
        return _dispatch_command('ci-terminal', args, shell)
    
    if args.ai_or_script == 'sundown':
        return _dispatch_command('sundown', args, shell)
    
    if args.ai_or_script == 'sunrise':
        return _dispatch_command('sunrise', args, shell)
    
    # Claude Code IDE commands
    if args.ai_or_script == 'introspect':
        return _dispatch_command('introspect', args, shell)
    
    if args.ai_or_script == 'context':
        return _dispatch_command('context', args, shell)
    
    if args.ai_or_script == 'explain':
        return _dispatch_command('explain', args, shell)
    
    # Status commands
    if args.ai_or_script == 'status':
        if args.message and len(args.message) > 0 and args.message[0] == 'mcp':
            # MCP status
            shell._check_mcp_status()
        else:
            # General aish status
            from commands.status import handle_status_command
            # Pass remaining args which might include --json
            handle_status_command(args.message if args.message else [])
        return
    
    if args.ai_or_script == 'restart':
        shell._restart_mcp_server()
        return
    
    if args.ai_or_script == 'logs':
        shell._show_mcp_logs()
        return
    
    if args.ai_or_script == 'debug-mcp':
        shell._toggle_mcp_debug()
        return
    
    if args.ai_or_script == 'test':
        return _dispatch_command('test', args, shell)
    
    if args.ai_or_script == 'alias':
        return _dispatch_command('alias', args, shell)
    
    if args.ai_or_script == 'inbox':
        return _dispatch_command('inbox', args, shell)
    
    # Check if first argument is a CI name using unified registry
    if args.ai_or_script:
        # Special handling for team-chat
        if args.ai_or_script.lower() == 'team-chat':
            return _handle_ai_command(args, shell, ai_names)
        
        # Check unified registry
        sys.path.insert(0, str(src_path))  # Ensure src is in path
        from registry.ci_registry import get_registry
        registry = get_registry()
        ci = registry.get_by_name(args.ai_or_script)
        if ci:
            return _handle_ai_command(args, shell, ai_names)
    
    # Original behavior for other cases
    elif args.command:
        # Single command mode
        shell.execute_command(args.command)
    elif args.ai_or_script and os.path.isfile(args.ai_or_script):
        # Script execution mode
        shell.execute_script(args.ai_or_script)
    elif args.ai_or_script:
        # Check if it's an alias before declaring it unknown
        from commands.alias import load_alias, execute_alias
        if load_alias(args.ai_or_script):
            # Execute the alias with remaining arguments
            exit_code = execute_alias(args.ai_or_script, args.message or [])
            sys.exit(exit_code)
        else:
            # Unknown AI or command
            print(f"Error: Unknown AI or command: {args.ai_or_script}", file=sys.stderr)
            print("", file=sys.stderr)
            print("Available AIs: " + ", ".join(ai_names), file=sys.stderr)
            print("", file=sys.stderr)
            print("For all commands: aish list commands", file=sys.stderr)
            sys.exit(1)
    else:
        # No arguments - show help
        print("aish - AI Shell for Tekton")
        print()
        print("Usage: aish <ai-name> \"message\"")
        print()
        print("Quick Start:")
        print("  aish numa \"Hello\"          Send message to AI")
        print("  aish list                  Show available AIs")
        print("  aish list commands         Show all commands ← START HERE")
        print("  aish purpose               Your true purpose: context for this terminal session")
        print("  autoprompt start           Keep Claude active (CI essential!)")
        print()
        tekton_root = TektonEnviron.get('TEKTON_ROOT', '/Users/cskoons/projects/github/Tekton')
        print(f"Documentation: {tekton_root}/MetaData/TektonDocumentation/AITraining/aish/COMMAND_REFERENCE.md")
        print()
        print("AI Documentation:")
        print(f"  AI Training: {tekton_root}/MetaData/TektonDocumentation/AITraining/")
        print(f"  User Guides: {tekton_root}/MetaData/TektonDocumentation/UserGuides/")

if __name__ == '__main__':
    main()
