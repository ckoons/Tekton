#!/usr/bin/env python3
"""
aish - The AI Shell
Main entry point for the AI shell interpreter.
"""

import sys
import os
import argparse
from pathlib import Path

# Try to import landmarks if available
try:
    from landmarks import architecture_decision, integration_point, api_contract, state_checkpoint
except ImportError:
    # Landmarks not available, create no-op decorators
    def architecture_decision(name, description, rationale=""):
        def decorator(func):
            return func
        return decorator
    
    def integration_point(name, description, rationale=""):
        def decorator(func):
            return func
        return decorator
    
    def api_contract(name, description, rationale=""):
        def decorator(func):
            return func
        return decorator
    
    def state_checkpoint(name, description, rationale=""):
        def decorator(func):
            return func
        return decorator


# Get the real path of the script (follows symlinks)
script_path = Path(__file__).resolve()
aish_root = script_path.parent
src_path = aish_root / 'src'

# Add src to path
sys.path.insert(0, str(src_path))

# Add parent paths to find shared module (we're in $TEKTON_ROOT/shared/aish)
tekton_root_for_import = aish_root.parent.parent  # Go up to $TEKTON_ROOT
if tekton_root_for_import.exists() and (tekton_root_for_import / 'shared').exists():
    sys.path.insert(0, str(tekton_root_for_import))

# Perform TektonEnvironLock.load() to ensure TektonEnviron is available
from shared.env import TektonEnvironLock, TektonEnviron
TektonEnvironLock.load() 

# Trust TEKTON_ROOT from environment
env_tekton_root = TektonEnviron.get('TEKTON_ROOT')
if not env_tekton_root:
    print(f"Error: TEKTON_ROOT environment variable not set")
    print(f"Please set TEKTON_ROOT to your Tekton installation directory")
    sys.exit(1)

tekton_root = Path(env_tekton_root)

# Verify that aish exists at the expected location
expected_aish = tekton_root / 'shared' / 'aish' / 'aish'
if not expected_aish.exists():
    print(f"Error: aish not found at expected location")
    print(f"  TEKTON_ROOT: {tekton_root}")
    print(f"  Expected aish at: {expected_aish}")
    print(f"  Please ensure TEKTON_ROOT points to a valid Tekton installation")
    sys.exit(1)

# Add tekton_root to path for imports
if tekton_root.exists() and (tekton_root / 'shared').exists():
    sys.path.insert(0, str(tekton_root))

from core.shell import AIShell
from core.version import __version__


# Landmark: Command Type Dispatch Router - Routes to appropriate handlers
def _dispatch_command(command_type, args, shell):
    """Dispatch command to appropriate handler based on type."""
    if command_type == 'forward':
        from commands.forward import handle_forward_command
        return handle_forward_command(args.message or [])
    elif command_type == 'unforward':
        from commands.forward import handle_unforward_command
        return handle_unforward_command(args.message or [])
    elif command_type == 'prompt':
        from commands.prompt import handle_prompt_command
        return handle_prompt_command(args.message or [])
    elif command_type == 'purpose':
        from commands.purpose import handle_purpose_command
        return handle_purpose_command(args.message or [])
    elif command_type == 'terma':
        from commands.terma import handle_terma_command
        return handle_terma_command(args.message)
    elif command_type == 'review':
        from commands.review import handle_command as handle_review_command
        return handle_review_command(args.message or [])
    return False


# Landmark: AI Message Input Collection - Priority: args > piped stdin > interactive
def _collect_ai_input(args, component):
    """Collect input for AI from various sources."""
    # Get input from message args first, then stdin, then interactive
    if args.message:
        # Message provided as arguments - this takes priority
        input_data = ' '.join(args.message).strip()
        if args.debug:
            print(f"[DEBUG] Using message args: {args.message}")
            print(f"[DEBUG] Joined as: '{input_data}'")
    elif not sys.stdin.isatty():
        # Data might be piped in
        # Try to read with a very short timeout to avoid hanging
        import select
        if select.select([sys.stdin], [], [], 0.0)[0]:
            input_data = sys.stdin.read().strip()
            if args.debug:
                print(f"[DEBUG] Got piped input: '{input_data}'")
        else:
            # No data in pipe, treat as interactive
            print(f"[aish] Entering interactive mode with {component}")
            print("Type your message and press Ctrl+D when done:")
            input_data = sys.stdin.read().strip()
    else:
        # Interactive mode with specific AI
        print(f"[aish] Entering interactive mode with {component}")
        print("Type your message and press Ctrl+D when done:")
        input_data = sys.stdin.read().strip()
    
    return input_data


# Landmark: AI Communication Handler - Routes to team-chat or individual AIs
def _handle_ai_command(args, shell, ai_names):
    """Handle command directed at a specific AI."""
    component = args.ai_or_script.lower()
    
    # Special handling for terma commands
    if component == 'terma':
        _dispatch_command('terma', args, shell)
        return
    
    # Check for help command
    if args.message and args.message[0] == "help":
        print(f"Usage: aish {component} [message]")
        tekton_root = TektonEnviron.get('TEKTON_ROOT', '/Users/cskoons/projects/github/Tekton')
        print(f"AI Training: {tekton_root}/MetaData/TektonDocumentation/AITraining/{component}/")
        print(f"User Guides: {tekton_root}/MetaData/TektonDocumentation/UserGuides/{component}/")
        return
    
    # Collect input from various sources
    input_data = _collect_ai_input(args, component)
    
    # Check if we actually have data
    if not input_data:
        print(f"aish: No message provided for {component}", file=sys.stderr)
        sys.exit(1)
    
    # Send directly to AI (no synthetic pipeline)
    if component == 'team-chat':
        shell.broadcast_message(input_data)
    else:
        shell.send_to_ai(component, input_data)


# Landmark: aish Command Entry Point - Main orchestration for all commands
def main():
    parser = argparse.ArgumentParser(
        description='aish - The AI Shell\n\nProvides AI capabilities in your terminal through the Tekton platform.',
        epilog='''Examples:
  aish                      # Start interactive AI shell
  aish apollo "question"    # Send question to Apollo AI
  echo "data" | aish athena # Pipe data to Athena AI
  aish team-chat "hello"    # Broadcast to all AIs
  aish -l                   # List available AIs
  aish script.ai            # Run AI script file

Available AIs: numa, tekton, prometheus, telos, metis, harmonia,
               synthesis, athena, sophia, noesis, engram, apollo,
               rhetor, penia, hermes, ergon, terma

Environment variables:
  RHETOR_ENDPOINT    # Override default Rhetor endpoint
  AISH_ACTIVE        # Set by aish-proxy when active
  AISH_DEBUG         # Enable debug output''',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        'ai_or_script',
        nargs='?',
        help='AI name (apollo, athena, etc.) or script file'
    )
    
    parser.add_argument(
        'message',
        nargs='*',
        help='Message to send to AI'
    )
    
    parser.add_argument(
        '-c', '--command',
        help='Execute a single AI pipeline command and exit'
    )
    
    parser.add_argument(
        '-v', '--version',
        action='version',
        version=f'aish {__version__}'
    )
    
    parser.add_argument(
        '-d', '--debug',
        action='store_true',
        help='Enable debug output'
    )
    
    parser.add_argument(
        '-r', '--rhetor',
        default=None,
        help='Rhetor endpoint (default: TEKTON_RHETOR_PORT env var or http://localhost:8003)'
    )
    
    parser.add_argument(
        '-l', '--list-ais',
        action='store_true',
        help='List available AI specialists and exit'
    )
    
    args = parser.parse_args()
    
    # Create shell instance
    shell = AIShell(
        rhetor_endpoint=args.rhetor,
        debug=args.debug
    )
    
    # Handle general help command
    if args.ai_or_script == "help":
        print("Usage: aish [options] [component] [command/message]")
        tekton_root = TektonEnviron.get('TEKTON_ROOT', '/Users/cskoons/projects/github/Tekton')
        print(f"AI Training: {tekton_root}/MetaData/TektonDocumentation/AITraining/aish/")
        print(f"User Guides: {tekton_root}/MetaData/TektonDocumentation/UserGuides/aish/")
        return
    
    # Handle special commands
    if args.list_ais:
        shell._list_ais()
        return
    
    # Known AI names with their roles (all lowercase for comparison)
    ai_names = ['numa',        # Companion
                'tekton',      # Projects
                'prometheus',  # Planning
                'telos',       # Requirements
                'metis',       # Workflows
                'harmonia',    # Orchestration
                'synthesis',   # Integration
                'athena',      # Knowledge
                'sophia',      # Learning
                'noesis',      # Discovery
                'engram',      # Memory
                'apollo',      # Attention/Prediction
                'rhetor',      # LLM/Prompt/Context
                'penia',       # LLM Cost
                'hermes',      # Messages/Data
                'ergon',       # Agents/Tools/MCP
                'terma',       # Terminal
                'hephaestus',  # UI/DevTools
                'team-chat']   # Broadcast to all
    
    # Handle special commands first
    if args.ai_or_script == 'whoami':
        # Show terminal name from environment
        terminal_name = TektonEnviron.get('TERMA_TERMINAL_NAME', 'Not in terma')
        print(terminal_name)
        return
    
    if args.ai_or_script == 'list':
        # Handle list commands
        if args.message and len(args.message) > 0 and args.message[0] == 'commands':
            # Show command reference
            print("aish Command Reference")
            print("=" * 50)
            print()
            print("CORE COMMANDS:")
            print("  aish                           Show help")
            print("  aish whoami                    Show identity information")
            print("  aish list                      List available AI components")
            print("  aish list commands             Show this command reference")
            print("  aish <ai> \"message\"            Send message to AI")
            print()
            print("FORWARDING:")
            print("  aish forward <ai> <terminal>   Forward AI messages to terminal")
            print("  aish forward list              Show active forwards")
            print("  aish forward remove <ai>       Remove forwarding")
            print("  aish unforward <ai>            Remove forwarding (alternative)")
            print()
            print("Purpose :")
            print("  aish purpose                   Get terminal purpose: context for currentteminal session")
            print("  aish purpose <name>            Get short form terminal purpose of <name>")
            print("  aish purpose <name> \"roles\"    Set terminal purpose/roles")
            print()
            print("TERMINAL:")
            print("  aish terma inbox               Show terminal inbox")
            print("  aish terma send <name> \"msg\"   Send inter-terminal message")
            print("  aish terma broadcast \"msg\"     Broadcast to all terminals")
            print("  aish terma inbox               Show terminal inbox")
            print()
            print("SESSION CAPTURE:")
            print("  aish review start              Start recording terminal session")
            print("  aish review stop               Stop recording and save session")
            print("  aish review list               List recent session recordings")
            print()
            print("PRODUCTIVITY:")
            print("  autoprompt start               Keep Claude CI active (default: 2s)")
            print("  autoprompt stop                Stop autoprompt")
            print("  autoprompt status              Check autoprompt status")
            print()
            print("ADVANCED:")
            print("  echo \"msg\" | aish <ai>         Pipe input to AI")
            print("  aish <ai1> | aish <ai2>        Chain AI responses")
            print("  aish team-chat \"message\"       Broadcast to all AIs")
            print()
            tekton_root = TektonEnviron.get('TEKTON_ROOT', '/Users/cskoons/projects/github/Tekton')
            print(f"Full documentation: {tekton_root}/MetaData/TektonDocumentation/AITraining/aish/COMMAND_REFERENCE.md")
            return
        else:
            # Show available AIs
            print("Available AI Components:")
            print()
            print("Core AIs:")
            print("  numa         - Companion AIi for Tekton Project")
            print("  tekton       - Tekton Multi-AI Engineering Platform")
            print("  prometheus   - Forward planning and foresight")
            print("  telos        - Purpose and completion")
            print("  metis        - Analysis and insight")
            print("  harmonia     - Balance and system harmony")
            print("  synthesis    - Integration and coordination")
            print("  athena       - Strategic wisdom and decision making")
            print("  sophia       - Wisdom and knowledge")
            print("  noesis       - Understanding and comprehension")
            print("  engram       - Memory and persistence")
            print("  apollo       - Predictive intelligence and attention")
            print("  rhetor       - Communication and prompt optimization")
            print("  penia        - Resource management")
            print("  hermes       - Messaging and communication")
            print("  ergon        - Work execution and tools")
            print()
            print("Infrastructure:")
            print("  terma        - Terminal management")
            print("  hephaestus   - User interface")
            print()
            print("Special:")
            print("  team-chat    - Broadcast to all AIs")
            print("  project      - Managed Project CIs")
            print()
            print("For all commands: aish list commands")
            return
    
    if args.ai_or_script == 'forward':
        return _dispatch_command('forward', args, shell)
    
    if args.ai_or_script == 'unforward':
        return _dispatch_command('unforward', args, shell)
    
    if args.ai_or_script == 'prompt':
        return _dispatch_command('prompt', args, shell)
    
    if args.ai_or_script == 'purpose':
        return _dispatch_command('purpose', args, shell)
    
    if args.ai_or_script == 'review':
        return _dispatch_command('review', args, shell)
    
    # Check if first argument is an AI name (case-insensitive)
    if args.ai_or_script and args.ai_or_script.lower() in ai_names:
        return _handle_ai_command(args, shell, ai_names)
    
    # Original behavior for other cases
    elif args.command:
        # Single command mode
        shell.execute_command(args.command)
    elif args.ai_or_script and os.path.isfile(args.ai_or_script):
        # Script execution mode
        shell.execute_script(args.ai_or_script)
    elif args.ai_or_script:
        # Unknown AI or command
        print(f"Error: Unknown AI or command: {args.ai_or_script}", file=sys.stderr)
        print("", file=sys.stderr)
        print("Available AIs: " + ", ".join(ai_names), file=sys.stderr)
        print("", file=sys.stderr)
        print("For all commands: aish list commands", file=sys.stderr)
        sys.exit(1)
    else:
        # No arguments - show help
        print("aish - AI Shell for Tekton")
        print()
        print("Usage: aish <ai-name> \"message\"")
        print()
        print("Quick Start:")
        print("  aish numa \"Hello\"          Send message to AI")
        print("  aish list                  Show available AIs")
        print("  aish list commands         Show all commands ‚Üê START HERE")
        print("  aish purpose               Your true purpose: context for this terminal session")
        print("  autoprompt start           Keep Claude active (CI essential!)")
        print()
        tekton_root = TektonEnviron.get('TEKTON_ROOT', '/Users/cskoons/projects/github/Tekton')
        print(f"Documentation: {tekton_root}/MetaData/TektonDocumentation/AITraining/aish/COMMAND_REFERENCE.md")
        print()
        print("AI Documentation:")
        print(f"  AI Training: {tekton_root}/MetaData/TektonDocumentation/AITraining/")
        print(f"  User Guides: {tekton_root}/MetaData/TektonDocumentation/UserGuides/")

if __name__ == '__main__':
    main()
